{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf19524-2fb9-4cdc-b8ed-e83b4843b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Function to clean and collect reviews from the HTML\n",
    "def clean_reviews(html_text):\n",
    "    script_tags = html_text.find_all('script', type='application/ld+json')\n",
    "    if len(script_tags) < 2:\n",
    "        return []\n",
    "\n",
    "    reviews_json = script_tags[1].string\n",
    "    if not reviews_json:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        reviews_data = json.loads(reviews_json)\n",
    "        reviews = reviews_data.get('review', reviews_data.get('reviews', []))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "        return []\n",
    "\n",
    "    data = []\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            author = review['author']['name'] if isinstance(review['author'], dict) else review['author']\n",
    "            data.append({\n",
    "                'author': author,\n",
    "                'review': review['description'],\n",
    "                'rating': review['reviewRating']['ratingValue']\n",
    "            })\n",
    "        except KeyError as e:\n",
    "            print(f\"Key error: {e}\")\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "# Function to save DataFrame to CSV\n",
    "def save_df(file_name, df):\n",
    "    # Sanitize file_name by removing invalid characters\n",
    "    file_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", file_name)\n",
    "    if not os.path.exists(\"Reviews\"):\n",
    "        os.makedirs(\"Reviews\")\n",
    "    df.to_csv(f\"Reviews/{file_name}.csv\", index=False)\n",
    "\n",
    "# Function to scrape reviews using requests\n",
    "def get_reviews(url, max_reviews, sort='popular'):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) '\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                      'Chrome/83.0.4103.97 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    sort_option = '&sort=rd' if sort == 'popular' else '&sort=dd'\n",
    "    \n",
    "    reviews = []\n",
    "    seen_reviews = set()\n",
    "    page_number = 1\n",
    "    restaurant_name = \"\"\n",
    "\n",
    "    retries = 3  # Number of retries\n",
    "    timeout = 10  # Timeout in seconds\n",
    "\n",
    "    while len(reviews) < max_reviews:\n",
    "        page_url = f\"{url}?page={page_number}{sort_option}\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(page_url, headers=headers, timeout=timeout)\n",
    "                response.raise_for_status()\n",
    "                break  # If the request was successful, break out of the retry loop\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Request failed (attempt {attempt+1} of {retries}): {e}\")\n",
    "                if attempt == retries - 1:\n",
    "                    return pd.DataFrame(reviews, columns=['author', 'review', 'rating'])\n",
    "                time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "\n",
    "        html_text = BeautifulSoup(response.text, 'html.parser')\n",
    "        title_tag = html_text.head.find('title')\n",
    "        if title_tag and not restaurant_name:\n",
    "            restaurant_name = title_tag.text.split(\"|\")[0].strip()\n",
    "\n",
    "        data = clean_reviews(html_text)\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        # Filter out duplicate reviews\n",
    "        unique_data = [review for review in data if review['review'] not in seen_reviews]\n",
    "        seen_reviews.update(review['review'] for review in unique_data)\n",
    "        if not unique_data:\n",
    "            break  # Stop if no new unique reviews are found\n",
    "\n",
    "        reviews.extend(unique_data)\n",
    "        page_number += 1\n",
    "\n",
    "    if not restaurant_name:\n",
    "        restaurant_name = \"Restaurant_Reviews\"\n",
    "    \n",
    "    review_df = pd.DataFrame(reviews[:max_reviews])\n",
    "\n",
    "    save_df(restaurant_name, review_df)\n",
    "\n",
    "    return review_df\n",
    "\n",
    "# Main scraping function using Selenium\n",
    "def scrape_zomato_reviews(url):\n",
    "    # Initialize lists to store data\n",
    "    all_rest_name = []\n",
    "    all_ratings = []\n",
    "    all_reviews = []\n",
    "\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Navigate to the restaurant link\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    scroll_pause_time = 1.8\n",
    "    screen_height = driver.execute_script(\"return window.screen.height;\")\n",
    "    i = 1\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, {0});\".format(screen_height * i))\n",
    "        i += 1\n",
    "        time.sleep(scroll_pause_time)\n",
    "        scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "        if (screen_height) * i > scroll_height:\n",
    "            break\n",
    "\n",
    "    # Create a soup object\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    divs = soup.findAll('div', class_='jumbo-tracker')\n",
    "\n",
    "    # Loop through restaurant divs and extract data\n",
    "    for parent in divs:\n",
    "        name_tag = parent.find(\"h4\")\n",
    "        if name_tag is not None:  # Check if the tag exists\n",
    "            rest_name = name_tag.text\n",
    "\n",
    "            link_tag = parent.find(\"a\")\n",
    "            base = \"https://www.zomato.com\"\n",
    "            rest_link = urljoin(base, link_tag.get('href'))\n",
    "\n",
    "            rating_tag = parent.div.a.next_sibling.div.div.div.div.div.div.div.text\n",
    "\n",
    "            all_rest_name.append(rest_name)\n",
    "            all_ratings.append(rating_tag)\n",
    "\n",
    "            # Navigate to the restaurant page\n",
    "            driver.get(rest_link)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Create a soup object for the restaurant page\n",
    "            rest_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # Find and click the reviews link to navigate to the reviews section\n",
    "            review_link_tag = rest_soup.find('a', string='Reviews')\n",
    "            if review_link_tag:\n",
    "                review_link = urljoin(base, review_link_tag['href'])\n",
    "\n",
    "                # Scrape reviews using requests\n",
    "                reviews_df = get_reviews(review_link, 500, sort='new')\n",
    "                all_reviews.append(reviews_df)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'names': all_rest_name,\n",
    "        'ratings': all_ratings,\n",
    "        'reviews': all_reviews\n",
    "    })\n",
    "\n",
    "    # Save restaurant data to a CSV file\n",
    "    df.to_csv(\"restaurant_data_with_reviews_hyderabad.csv\", index=False)\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_zomato_reviews(\"https://www.zomato.com/hyderabad/somajiguda-restaurants\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
